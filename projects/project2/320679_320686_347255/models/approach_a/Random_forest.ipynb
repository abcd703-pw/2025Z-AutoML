{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8561e19-164b-46e8-9391-6aa1b4cc03c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import numpy as np\n",
    "import openml\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from optuna.samplers import TPESampler, CmaEsSampler\n",
    "from plotly.io import show\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a4c51-1bd4-4f1f-84d6-aedc4f7dc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_prepare(openml_id):\n",
    "    dataset = openml.datasets.get_dataset(openml_id)\n",
    "    print(f\">>> {dataset.name} (ID: {openml_id})\")\n",
    "    X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format='dataframe')\n",
    "\n",
    "    num_cols = X.select_dtypes(include=['number']).columns\n",
    "    cat_cols = X.select_dtypes(include=['category', 'object']).columns\n",
    "\n",
    "    if len(num_cols) > 0:\n",
    "        imputer_num = SimpleImputer(strategy='mean')\n",
    "        X[num_cols] = imputer_num.fit_transform(X[num_cols])\n",
    "        scaler = MinMaxScaler()\n",
    "        X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "    if len(cat_cols) > 0:\n",
    "        imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "        X[cat_cols] = imputer_cat.fit_transform(X[cat_cols])\n",
    "        encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "        X[cat_cols] = encoder.fit_transform(X[cat_cols].astype(str))\n",
    "        \n",
    "    if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10ce90-72e4-4614-8a10-5b4e88d9c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # 1. Import właściwej klasy\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 206, 1740)\n",
    "    bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False]) \n",
    "    max_features = trial.suggest_float(\"max_features\", 0.323, 0.974)\n",
    "    min_samples_split = trial.suggest_float(\"min_samples_split\", 0.007, 0.513)\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        bootstrap=bootstrap,\n",
    "        max_features=max_features,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42,\n",
    "        n_jobs = 1\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='roc_auc',n_jobs=-1)\n",
    "    \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa125c-0e32-4522-9560-a13640d96d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "dataset_ids = [1590, 1461, 24, 40945, 31, 44, 1464, 37, 3, 59]\n",
    "results_list = []  \n",
    "\n",
    "for i in dataset_ids:\n",
    "    X, y = fetch_and_prepare(i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "    study.optimize(objective, n_trials=80)\n",
    "\n",
    "    new_config = {\n",
    "        \"name\": f\"rf_100_ds_{i}\", \n",
    "        \"class\": \"sklearn.ensemble.RandomForestClassifier\",\n",
    "        \"params\": {\n",
    "             \n",
    "        }\n",
    "    }\n",
    "    \n",
    "    new_config[\"params\"].update(study.best_params)\n",
    "\n",
    "    \n",
    "    results_list.append(new_config)\n",
    "\n",
    "with open('all_configs_rf.json', 'w') as f:\n",
    "    json.dump(results_list, f, indent=2)\n",
    "\n",
    "print(\"Plik JSON zawiera teraz wszystkie 10 konfiguracji.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1ea6b-d315-45a4-8a8e-fc7974a30d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
