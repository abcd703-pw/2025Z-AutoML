{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed6ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import make_column_transformer, make_column_selector, ColumnTransformer \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler \n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_val_score, ParameterSampler\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "import openml\n",
    "import json\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import loguniform, randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b2bebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SEARCH_SPACE = [\n",
    "    # ===== LINEAR / HIGH-DIM =====\n",
    "    {\n",
    "        \"name\": \"logreg\",\n",
    "        \"class\": \"sklearn.linear_model.LogisticRegression\",\n",
    "        \"search_space\": {\n",
    "            \"C\": loguniform(1e-4, 1e2),\n",
    "            \"penalty\": [\"l1\", \"l2\"],\n",
    "            \"solver\": [\"liblinear\"],\n",
    "            \"max_iter\": [2000]\n",
    "        },\n",
    "        \"n_iter\": 20\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"linear_svm\",\n",
    "        \"class\": \"sklearn.svm.LinearSVC\",\n",
    "        \"search_space\": {\n",
    "            \"C\": loguniform(1e-4, 1e2)\n",
    "        },\n",
    "        \"n_iter\": 20\n",
    "    },\n",
    "\n",
    "    # ===== INSTANCE-BASED =====\n",
    "    {\n",
    "        \"name\": \"knn\",\n",
    "        \"class\": \"sklearn.neighbors.KNeighborsClassifier\",\n",
    "        \"search_space\": {\n",
    "            \"n_neighbors\": randint(3, 50),\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"p\": [1, 2]\n",
    "        },\n",
    "        \"n_iter\": 20\n",
    "    },\n",
    "\n",
    "    # ===== TREE ENSEMBLES =====\n",
    "    {\n",
    "        \"name\": \"random_forest\",\n",
    "        \"class\": \"sklearn.ensemble.RandomForestClassifier\",\n",
    "        \"search_space\": {\n",
    "            \"n_estimators\": randint(100, 800),\n",
    "            \"max_depth\": [None] + list(range(3, 20)),\n",
    "            \"min_samples_leaf\": randint(1, 20),\n",
    "            \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "        },\n",
    "        \"n_iter\": 20\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extra_trees\",\n",
    "        \"class\": \"sklearn.ensemble.ExtraTreesClassifier\",\n",
    "        \"search_space\": {\n",
    "            \"n_estimators\": randint(200, 800),\n",
    "            \"max_depth\": [None] + list(range(3, 20)),\n",
    "            \"min_samples_leaf\": randint(1, 20),\n",
    "            \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "        },\n",
    "        \"n_iter\": 20\n",
    "    },\n",
    "\n",
    "    # ===== GRADIENT BOOSTING =====\n",
    "    {\n",
    "        \"name\": \"lightgbm\",\n",
    "        \"class\": \"lightgbm.LGBMClassifier\",\n",
    "        \"search_space\": {\n",
    "            \"n_estimators\": randint(100, 800),\n",
    "            \"num_leaves\": randint(16, 256),\n",
    "            \"learning_rate\": loguniform(1e-3, 0.3),\n",
    "            \"min_child_samples\": randint(5, 100),\n",
    "            \"subsample\": uniform(0.6, 0.4),\n",
    "            \"colsample_bytree\": uniform(0.6, 0.4)\n",
    "        },\n",
    "        \"n_iter\": 20\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d51080b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_configs(global_seed=42):\n",
    "    configs = []\n",
    "\n",
    "    for model_def in MODEL_SEARCH_SPACE:\n",
    "        sampler = ParameterSampler(\n",
    "            model_def[\"search_space\"],\n",
    "            n_iter=model_def[\"n_iter\"],\n",
    "            random_state=global_seed\n",
    "        )\n",
    "\n",
    "        for params in sampler:\n",
    "            configs.append({\n",
    "                \"name\": model_def[\"name\"],\n",
    "                \"class\": model_def[\"class\"],\n",
    "                \"params\": params\n",
    "            })\n",
    "\n",
    "    return configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb53dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openml_datasets(max_datasets=20):\n",
    "    suite = openml.study.get_suite(99)  # OpenML-CC18\n",
    "    datasets = []\n",
    "\n",
    "    for did in suite.data[:max_datasets]:\n",
    "        dataset = openml.datasets.get_dataset(did)\n",
    "        X, y, _, _ = dataset.get_data(\n",
    "            dataset_format=\"dataframe\",\n",
    "            target=dataset.default_target_attribute\n",
    "        )\n",
    "        datasets.append((dataset.name, X, y))\n",
    "\n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d881c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_class_path, params, X, y, seed=42):\n",
    "    module_name, class_name = model_class_path.rsplit(\".\", 1)\n",
    "    cls = getattr(importlib.import_module(module_name), class_name)\n",
    "\n",
    "    model = cls(**params)\n",
    "    \n",
    "    num_pipeline = Pipeline(steps=[\n",
    "        ('impute', SimpleImputer()),\n",
    "        ('scale', MinMaxScaler())\n",
    "        ])\n",
    "\n",
    "\n",
    "    cat_pipeline= Pipeline(steps = [\n",
    "        ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "        ('one_hot', OneHotEncoder(handle_unknown='ignore', drop='first'))\n",
    "        ])\n",
    "\n",
    "\n",
    "    col_trans = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\n",
    "                \"numeric_preprocessing\",\n",
    "                num_pipeline,\n",
    "                make_column_selector(dtype_include=np.number),\n",
    "            ),\n",
    "            (\n",
    "                \"categorical_preprocessing\",\n",
    "                cat_pipeline,\n",
    "                make_column_selector(dtype_include=['category', 'object']),\n",
    "            ),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessing', col_trans),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        pipe,\n",
    "        X,\n",
    "        y,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return float(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a584471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(datasets, model_configs):\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    for ds_name, X, y in datasets:\n",
    "        print(f\"\\nDataset: {ds_name}\")\n",
    "\n",
    "        for cfg in tqdm(model_configs):\n",
    "            score = evaluate_model(\n",
    "                cfg[\"class\"],\n",
    "                cfg[\"params\"],\n",
    "                X,\n",
    "                y\n",
    "            )\n",
    "\n",
    "            key = (\n",
    "                cfg[\"class\"],\n",
    "                frozenset(cfg[\"params\"].items())\n",
    "            )\n",
    "\n",
    "            results[key].append(score)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5961b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_models(results, top_n=50):\n",
    "    summary = []\n",
    "\n",
    "    for (cls, params), scores in results.items():\n",
    "        summary.append({\n",
    "            \"class\": cls,\n",
    "            \"params\": dict(params),\n",
    "            \"datasets\": len(scores),\n",
    "            \"mean_balanced_accuracy\": float(np.mean(scores))\n",
    "        })\n",
    "\n",
    "    summary.sort(\n",
    "        key=lambda x: (x[\"datasets\"], x[\"mean_balanced_accuracy\"]),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return summary[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1eb99c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models_to_json(models, path=\"best_models.json\"):\n",
    "    output = []\n",
    "\n",
    "    for i, m in enumerate(models):\n",
    "        output.append({\n",
    "            \"name\": f\"model_{i}\",\n",
    "            \"class\": m[\"class\"],\n",
    "            \"params\": m[\"params\"]\n",
    "        })\n",
    "\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(output, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81cc17a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_openml_datasets(max_datasets=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97af5c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model configs: 120\n"
     ]
    }
   ],
   "source": [
    "MODEL_CONFIGS = prepare_model_configs(global_seed=42)\n",
    "print(f\"Total model configs: {len(MODEL_CONFIGS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc6b0e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: kr-vs-kp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [01:52<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: letter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [41:57<00:00, 20.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: balance-scale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [00:45<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: mfeat-factors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [30:24<00:00, 15.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: mfeat-fourier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [21:14<00:00, 10.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: breast-w\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [00:36<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: mfeat-karhunen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [16:34<00:00,  8.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: mfeat-morphological\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [04:17<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: mfeat-zernike\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [11:43<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: cmc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [01:40<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: optdigits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [11:23<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: credit-approval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [00:45<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: credit-g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [01:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: pendigits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [14:38<00:00,  7.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: diabetes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [00:42<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: spambase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [04:27<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: splice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [08:46<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: tic-tac-toe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [00:47<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: vehicle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [01:33<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: electricity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [18:26<00:00,  9.22s/it]\n"
     ]
    }
   ],
   "source": [
    "RESULTS = run_benchmark(datasets, MODEL_CONFIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d730b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_MODELS = select_top_models(RESULTS, top_n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed5576b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_to_json(TOP_MODELS, \"best_models.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kiddo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
